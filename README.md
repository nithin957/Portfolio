# Portfolio

# Sai Nithin Billi | Data Analyst
## [GitHub ðŸ”—](https://github.com/nithin957)|[Tableau ðŸ”—](https://public.tableau.com/app/profile/sai.nithin.billi/vizzes)

#### Technical Skills: Python, SQL, R, Tableau, Power BI, PyTorch, Excel, Pandas, NumPy, Matplotlib, Scikit-learn.

## Education
- Masters in Data Analytics | Clark University  (_May 2025_)								       		
- Bachelor of Technology | JNTUH  (_May 2022_)

## Projects
### FIFA Players Analytics â€“ R, Excel
[Link](https://github.com/nithin957/FIFA-Player-Performance-Analysis-and-Predictive-Modeling)
- Conducted extensive Exploratory Data Analysis (EDA) on 18,483 FIFA player records, identifying key correlations and patterns in player attributes, market values, and wages. 
- Developed a Logistic regression model to classify players with high or low wages with 0.93 AUC score and a regularization model to predict 
players' potential ratings with 98.92% accuracy using R.
- Performed hypothesis testing to compare overall ratings between European and South American players, revealing statistically significant differences (p-value <0.05) and providing insights for regional scouting strategies.

### Used Car Price Analysis â€“ Python, Pandas, Matplotlib
[Link](https://github.com/nithin957/data-analysis-using-python)
- Cleaned and analyzed over 300,000 used car listings from eBay Germany using Pandas and NumPy.
- Identified price outliers, and missing values, and engineered features like age and mileage per year.
- Built regression models to predict car prices and visualized market trends with Matplotlib.

### Product Sales & Market Demographics Dashboard â€“ Tableau
[Link](https://github.com/nithin957/Product-Sales-Customer-Demographics-and-Market-Analysis-Dashboard-Tableau)
- Developed an interactive multi-dashboard solution to analyze product sales, customer demographics, and regional performance using Tableau and the Sample Superstore dataset.
- Uncovered key business insights such as the impact of education and occupation on sales, regional revenue trends, and customer growth patterns.
- Implemented advanced visualizations (dual-axis charts, cohort analysis, bar-in-bar, lollipop charts) and interactivity features (filters, parameters, drill-downs) to support strategic decision-making.

### Adaptive Loss vs ArcFace Loss â€“ PyTorch, Deep Learning
[Link](https://github.com/nithin957/Adaptive-vs-Arc-Loss-Cifar10-MNIST)
- Designed and implemented Adaptive Loss (AdaLoss) to dynamically adjust angular margins during training, improving upon traditional ArcFace Loss.
- Applied both loss functions to CNN models for MNIST and CIFAR-10, achieving notable accuracy improvements:
  - MNIST: 99.11% (AdaLoss) vs 97.86% (ArcFace)
  - CIFAR-10: 68.13% (AdaLoss) vs 62.35% (ArcFace)
- Demonstrated faster convergence and better generalization of AdaLoss, especially in high intra-class variance scenarios.
- Built and trained models using PyTorch, with complete evaluation pipelines and visual analysis.

### Swin Transformer vs Vision Transformer (ViT) â€“ PyTorch, Deep Learning
[Link](https://github.com/nithin957/Swin-vs-ViT-cifar10)
- Conducted a head-to-head comparison of Vision Transformer (ViT) and Swin Transformer on the CIFAR-10 image classification task to evaluate performance, training dynamics, and model complexity.
- ViT achieved higher test accuracy (91.65%) and faster convergence than Swin Transformer (90.46%), demonstrating superior performance under identical training conditions.
- Analyzed architectural trade-offs:
  - ViT: Flat structure, global self-attention, higher computational cost
  - Swin: Hierarchical, window-based attention with translation-invariant design
- Implemented both models in PyTorch, tracked metrics including accuracy, loss, and convergence over 200 epochs.
- Provided visual comparison of training curves, highlighting ViTâ€™s faster learning rate and lower loss values.



## Work Experience
 Data Analyst Intern @ Mc Kesson (_Sep 2024 - Apr 2025_)
-  Automated daily and weekly reports using Python, Excel VBA, and Google Apps Script, reducing manual intervention by over 60% and improving data reliability. 
- Developed time-series forecasting models (ARIMA, Prophet) to predict volume trends, enabling proactive supply chain planning and reduced operational delays. 
- Built and maintained Power BI dashboards to visualize critical KPIs across procurement, logistics, and inventory control, used by senior leadership for strategic planning. 
- Conducted Statistical Process Control (SPC) analyses and process capability studies for logistics data, identifying bottlenecks and ensuring performance consistency. 
- Collaborated with cross-functional teams to implement data validation checks and resolve missing/erroneous data issues in Snowflake. 
- Supported system data integrity by documenting changes and contributing to internal QA protocols across data pipelines. 

 Data Analyst @ Cognier Insights (_Dec 2021 - Jun 2023_)
- Led analytical projects involving large-scale manufacturing and e-commerce data; performed multivariate analysis and SPC to support client performance reviews and CAPA processes. 
- Built automated ETL workflows using Python and SQL to integrate CRM, ERP, and transaction system data, reducing manual errors and improving refresh cycle times by 80%. 
- Developed process capability dashboards using Spotfire and Tableau to identify anomalies in Critical Quality Attributes (CQA) and improve process stability. 
- Created validation documentation and supported change control processes for analytics workflows in compliance with GMP standards. 
- Used STATISTICA Workspace and JMP for hypothesis testing, regression, and visualization of quality metrics across production cycles. 
- Built SEEQ visualizations and configured PI tags to track manufacturing sensor data for time-based trend analyses. 
- Worked with QA and engineering teams to clean Spotfire workspaces, troubleshoot data gaps, and maintain compliance-ready dashboards.

 Data Analyst Intern @ Cognier Insights (_Mar 2020 - sep 2020_)
 - Conducted deep-dive analyses of insurance claims and policy renewals using SQL and Excel, detecting fraud and reducing payout leakages by 10%. 
- Used Python (pandas, NumPy) for data cleansing and validation, ensuring compliance with internal QA and actuarial standards. 
- Automated legacy reporting tools using Excel VBA and macros, saving over 20 hours/month in manual work. 
- Created performance dashboards using Spotfire and Power BI for operational decision-making and process optimization. 
- Collaborated on review and compilation of statistical reports as part of internal product/process audits. 
